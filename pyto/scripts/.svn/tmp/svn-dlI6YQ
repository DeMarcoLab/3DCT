#!/usr/bin/env python
"""

Makes layers in a given region starting from one or between two specified boundaries.
Also analyzes position of given segments in respect to the layers  


$Id$
Author: Vladan Lucic 
"""
__version__ = "$Revision$"

import sys
import os
import os.path
import time
import platform
import pickle
from copy import copy, deepcopy 
import logging

import numpy
import pyto

logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s %(levelname)s %(message)s',
                    datefmt='%d %b %Y %H:%M:%S')


##############################################################
#
# Parameters
#
##############################################################

############################################################
#
# Image (grayscale) file. If it isn't in em or mrc format, format related
# variables (shape, data type, byte order and array order) need to be given
# (see labels file section below).
#

# name of the image file
image_file = "../3d/and-1-6.mrc"

###############################################################
#
# Boundaries file, used to make layers 
#
# Can be either an pickle file containing Segments object (extension pkl), or
# (one or more) file(s) containing data array.  
#
# If the file is a pickle file, parameters shape, data type, byte order and array 
# order are disregarded. If the file is in em or mrc format, these parameters 
# are not necessary and should be set to None. If any of these parameters is 
# specified, it will override the corresponding value specified in the header.
#
# If multiple boundaries files are used, boundaries_file, boundary_ids have to be 
# tuples (or lists) of the same lenght
#

# name of (one or more) file(s) containing boundaries. It can be a pickle file 
# containing Segment object, or (one or more) files containing boundaries array(s).
#boundaries_file = 'boundaries.pkl'   # Segment object pickle file
boundaries_file = '../viz/reconstruction_and-1-6_int-1-label_vesicles-membrane_2AZ_psd.raw'   # one boundaries file
#boundaries_file = ("bound_1.dat", "bound_2.dat", "bound_3.dat")  # more boundaries

# boundaries file dimensions
boundaries_shape = (260, 260, 100)

# boundaries file data type (e.g. 'int8', 'uint8', 'int16', 'int32', 'float64') 
boundaries_data_type = 'uint8'

# boundaries file byteOrder ('<' for little-endian, '>' for big-endian)
boundaries_byte_order = '<'

# boundaries file array order ('FORTRAN' for x-axis fastest, 'C' for z-axis fastest)
boundaries_array_order = 'FORTRAN'

# offset of boundaries in respect to the data 
boundaries_offset = None             # no offset
#boundaries_offset = [10, 20, 30]    # offset specified

# ids of all segments in the boundaries file that need to be kept 
#boundary_ids = 1           # usual from for ma
boundary_ids = [1,66,67,68,69] + range(2,15)

# id shift in each subsequent boundaries file (in case of multiple boundary files) 
boundaries_shift = None    # shift is determined automatically
#boundaries_shift = 300

########################################################
#
# Layer parameters (set boundary_id_1 to None for no layers)
#

# segment id of a boundary 1 used to make layers
#boundary_id_1 = None       # don't make layers at all
boundary_id_1 = 1           # make layers

# segment id of a boundary 1 used to make layers
boundary_id_2 = None        # make layers from boundary_id_1
#boundary_id_2 = 4           # make layers between boundary_id_1 and boundary_id_2

# one or more ids of regions where layers are formed (0 is not recommended)
# if using multiple bondary files, enter shifted ids here
layers_mask_id = [69] + range(2,15)

# layer thickness
#layer_thickness = None     # thickness from num_layers (for layers between only)
layer_thickness = 1         # for layers from only

# number of layers (only if layer_thickness is None and if layers are formed between
# boundary_id_1 and boundary_id_2 
num_layers = 40

# number of extra layers (on each side if layers between) formed on boundary(ies)
# and on extra_layers mask(s)
#num_extra_layers = 0    # no extra regions
num_extra_layers = 0

# ids of a region where extra layers are formed (in addition to boundary_id_1)
# (if 0 make sure segment_ids has all ids)
extra_layers_mask_id_1 = 67

# ids of a region where extra layers are formed (in addition to boundary_id_2)
# (if 0 make sure segment_ids has all ids)
extra_layers_mask_id_2 = None

###############################################################
#
# Segments file 
#
# Can be either one pickle file containing Segments object (extension pkl), or
# (one or more) file(s) containing data array.  
#
# If the file is a pickle file, parameters shape, data type, byte order and array 
# order are disregarded. If the file is in em or mrc format, these parameters 
# are not necessary and should be set to None. If any of these parameters is 
# specified, it will override the corresponding value specified in the header.
#
# If multiple segments files are used, segments_file, segments_ids have to be 
# tuples (or lists) of the same lenght
#

# name of (one or more) file(s) containing segments. It can be a pickle file 
# containing Segment object, or (one or more) files containing segments array(s).
segments_file = 'segments.pkl'   # Segment object pickle file
#segments_file = 'segments.em'   # one segments file
#segments_file = ("segments_1.dat", "segments_2.dat", "segments_3.dat")  # more segments

# segments file dimensions
segments_shape = None
#segments_shape = (260, 260, 100)

# segments file data type (e.g. 'int8', 'uint8', 'int16', 'int32', 'float16', 'float64') 
segments_data_type = None
#segments_data_type = 'uint8'

# segments file byteOrder ('<' for little-endian, '>' for big-endian)
segments_byte_order = None
#segments_byte_order = '<'

# segments file array order ('FORTRAN' for x-axis fastest, 'C' for z-axis fastest)
segments_array_order = None
#segments_array_order = 'FORTRAN'

# offset of segments in respect to the data 
segments_offset = None             # no offset
#segments_offset = [10, 20, 30]    # offset specified

# ids of segments in the segments file
segment_ids = None         # use all segments
#segment_ids = range(2,15) # use only these segments

# id shift in each subsequent segments file (in case of multiple segment files) 
segments_shift = None    # shift is determined automatically
#segments_shift = 400

###############################################################
#
# Output files: layers and results, Results file name is formed as:
#
#    <results_directory>/<results_prefix> + segments root + <results_suffix>
#

# layers file (pickle, em or mrc file)
layers_file = 'layers.em'

# results directory
results_directory = ''

# results file name prefix (no directory name)
results_prefix = ''

# results file name suffix
results_suffix = '_layers.dat'


################################################################
#
# Functions
#
################################################################

###########################################
#
# Read image file
#

def read_image():
    """
    Reads image file and returns an segmentation.Image object
    """
    image_file_o = pyto.io.ImageIO()
    image_file_o.read(file=image_file)
    image = pyto.segmentation.Grey(data=image_file_o.data)
    return image

###########################################
#
# Read segments and boundaries files
#

def read_segments(file_name, offset=None, ids=None, byte_order=None,  
                   data_type=None, array_order=None, shape=None, shift=None):
    """
    """
                  
    if os.path.splitext(file_name)[-1] == '.pkl':

        # read pickle file
        segments = pickle.load(open(file_name)).toSegment()
        if ids is not None:
            segments.setIds(ids=ids)
        multi_ids = [ids]

    else:

        # read array (labels) file(s)
        segments, multi_ids = read_array_segments(file_name=file_name, 
                     ids=ids, byte_order=byte_order, data_type=data_type, 
                     array_order=array_order, shape=shape, shift=shift)

    return segments, multi_ids

def read_array_segments(file_name, offset=None, ids=None, byte_order=None,  
                        data_type=None, array_order=None, shape=None, shift=None):
    """
    Reads segments (labels) file(s)
    """

    # read
    if is_multi_file(file_name=file_name):
        segments, multi_ids = read_multi_segments(file_name=file_name, ids=ids,
                                  byte_order=byte_order, data_type=data_type,
                                  array_order=array_order, shape=shape, shift=shift)
    else:
        segments = read_single_segments(file_name=file_name, ids=ids,
                                       byte_order=byte_order, data_type=data_type,
                                       array_order=array_order, shape=shape)
        multi_ids = [ids]

    # offset
    segments.offset = offset

    return segments, multi_ids

def read_multi_segments(file_name, ids=None, byte_order=None, data_type=None, 
                        array_order=None, shape=None, shift=None):
    """
    Reads and initializes segments form multiple labels files.
    """

    # read all labels files and combine them in a single Segment object
    segments = pyto.segmentation.Segment()
    curr_shift = 0
    shifted_segment_ids = []
    for (l_name, single_ids, s_ids) in zip(file_name, ids, segment_ids):
        curr_segments = pyto.segmentation.Segment.read(file=l_name, ids=single_ids,
               clean=True, byteOrder=byte_order, dataType=data_type,
               arrayOrder=array_order, shape=shape)
        segments.add(new=curr_segments, shift=curr_shift, dtype='int16')
        shifted_segment_ids.append(numpy.array(s_ids) + curr_shift)
        if shift is None:
            curr_shift = None
        else:
            curr_shift += shift

    return segments, shifted_segment_ids
    
def read_single_segments(file_name, ids=None, byte_order=None, data_type=None, 
                         array_order=None, shape=None):
    """
    Reads and initializes segments form a sigle labels file.
    """

    # read file and make a Segment object
    segments = pyto.segmentation.Segment.read(file=file_name, clean=True, ids=ids,
               byteOrder=byte_order, dataType=data_type,
               arrayOrder=array_order, shape=shape)

    return segments

def is_multi_file(file_name):
    """
    Returns True if maultiple files are given.
    """
    if isinstance(file_name, str):
        return False
    elif isinstance(file_name, tuple) or isinstance(file_name, list):
        return True
    else:
        raise ValueError, str(file_name) + " has to be aither a string (one " \
              + "file) or a tuple (multiple files)."    

###########################################
#
# Analysis
#

def make_layers(segments):
    """
    """
    
    # save inset
    #segment_full_inset = segment.inset
    
    if boundary_id_2 is None:

        # segments from
        layers =  segments.makeLayersFrom(bound=boundary_id_1, mask=layers_mask_id, 
                  thick=layer_thickness, nLayers=num_layers,
                  nExtraLayers=num_extra_layers, extra=extra_layers_mask_id_1) 

    else:

        # segments between
        layers, dist =  segments.makeLayersBetween(bound_1=boundary_id_1, 
                  bound_2=boundary_id_2, mask=layers_mask_id, nLayers=num_layers,
                  nExtraLayers=num_extra_layers, extra_1=extra_layers_mask_id_1, 
                  extra_2=extra_layers_mask_id_2)

    return layers

def analyze(image, layers, segments):
    """
    """

    # layer density and volume
    layer_density = pyto.segmentation.Density()
    layer_density.calculate(image=image, segments=layers)

    # segments centers
    seg_mor = pyto.segmentation.Morphology(segments=segments)
    seg_mor.getCenter()

    # count segment centers in each layer
    segment_count = numpy.zeros(layers.maxId+1, dtype='int')
    for seg_id in segments.ids:
        layer_id = layers.data[tuple(seg_mor.center[seg_id])]
        segment_count[layer_id] += 1

    # get density of segment centers in each volume
    segment_count_per_volume = (1. * segment_count) / layer_density.volume

    # get volume occupied by all segments for each layer
    segments_vol = numpy.zeros(layers.maxId+1, dtype='int') - 1
    segments_bin = segments.data > 0
    for lay_id in layers.ids:
        segments_vol[lay_id] = (segments_bin & (layers.data == lay_id)).sum()

    # get a fraction of each layer volume that is occupied by segments
    overlap = numpy.true_divide(segments_vol, layer_density.volume)

    #
    return layer_density, segment_count, segment_count_per_volume, overlap

###########################################
#
# Write files
#

def get_results_file(extension=''):
    """
    
    """

    # extract root from the segments file
    (dir, base) = os.path.split(segments_file)
    (root, ext) = os.path.splitext(base)

    # figure out hierarchy file name
    results_base = results_prefix + root + results_suffix + extension
    results_file = os.path.join(results_directory, results_base)

    return results_file

def write_layers(layers):
    """
    """

    ext = os.path.splitext(layers_file)
    if ext == '.pkl':

        # pickle
        pickle.dump(layers, open(layers_file, 'w'))

    else:

        # write image file
        layers.data = numpy.asarray(layers.data, dtype='uint16')
        layers.write(file=layers_file)

def machine_info():
    """
    Returns machine name and machine architecture strings
    """
    mach = platform.uname() 
    mach_name = mach[1]
    mach_arch = str([mach[0], mach[4], mach[5]])

    return mach_name, mach_arch

def format_file_header(file_name, file_type, ids=None):

    if file_name is None: return []

    if is_multi_file(file_name=file_name):

        # multi file
        lines = ["# " + file_type + ":"]
        lines.extend(["#     " + name + " (" + \
                      time.asctime(time.localtime(os.path.getmtime(name))) + ")"\
                      for name in file_name])
        if ids is not None:
            lines.extend(["#     Ids:" + name + " (" + \
                          time.asctime(time.localtime(os.path.getmtime(name))) + ")"\
                          for name in file_name])

    else:

        # single_file
        file_time = time.asctime(time.localtime(os.path.getmtime(file_name)))
        lines = ["# " + file_type + ": " + file_name + " (" + file_time + ")"] 

    return lines

def format_layer_ids():
    """
    """

    lines = []
    lines.append("# Layer ids:")
    lines.append("#     - layers region: %d - %d" %
                 (num_extra_layers + 1, num_extra_layers + num_layers)) 
    lines.append("#     - extra layers:      %d - %d" % (1, num_extra_layers)) 

    if boundary_id_2 is not None:
        lines.append("#     - extra layers:      %d - %d" %
                     (num_extra_layers + num_layers + 1,
                      2 * num_extra_layers + num_layers)) 

    return lines
                    
def format_header(nested_segment_ids):
    """
    """

    lines = []

    # machine info
    mach_name, mach_arch = machine_info()
    lines.append("# Machine: " + mach_name + " " + mach_arch)

    # files
    lines.extend(format_file_header(file_name=image_file, file_type="Image"))
    lines.extend(format_file_header(file_name=boundaries_file, file_type="Boundaries"))
    lines.extend(format_file_header(file_name=segments_file, file_type="Segments"))
    lines.extend(format_file_header(file_name=layers_file, file_type="Layers (output)"))
    lines.extend(format_file_header(file_name=sys.modules[__name__].__file__,
                                  file_type="Input script"))                
    lines.append("# Working directory: " + os.getcwd())

    # segment ids:
    lines.append("#")
    if is_multi_file(file_name=segments_file):
        lines.append("# Segment ids:")
        lines.extend(["#     " + str(one_ids) for one_ids in nested_segment_ids])
    else:
        lines.append("# Segment ids: " + str(nested_segment_ids))
        
    # layer ids
    lines.append('#')
    lines.extend(format_layer_ids())

    # parameters

    return lines


def format_data(layers_density, segment_count, segment_count_per_volume, overlap,
                layer_ids):

    lines = ["#"]

    # table head
    lines.extend([\
        "#                  Layers                          Segments      ",
        "# Id            Grey value        Volume   Num Num/Vol  Vol fract",
        "#       mean   std    min    max                                 "]) 

    # data for individual neighbourhoods and whole segments
    out_vars = [layers_density.mean, layers_density.std, layers_density.min,
                layers_density.max, layers_density.volume,
                segment_count, segment_count_per_volume, overlap]
    out_format = '%4u  %6.2f %6.3f %6.2f %6.2f  %5d %4d %8.6f %7.5f'  
    lines.extend(pyto.io.util.arrayFormat(arrays=out_vars, format=out_format,
                                          indices=layer_ids, prependIndex=True))

    return lines

def write_results(layer_density, layer_ids, nested_segment_ids, segment_count,
                  segment_count_per_volume, overlap):

    # make header
    lines = ["#"]
    lines.extend(format_header(nested_segment_ids=nested_segment_ids))

    # make data part
    lines.append("#")
    lines.extend(format_data(layers_density=layer_density, layer_ids=layer_ids,
                     segment_count=segment_count,
                     segment_count_per_volume=segment_count_per_volume,
                     overlap=overlap))

    # write
    res_file = open(get_results_file(), 'w')
    for line in lines:
        res_file.write(line + os.linesep)
    res_file.flush()


################################################################
#
# Main function
#
###############################################################

def main():
    """
    Main function
    """

    # log machine name and architecture
    mach_name, mach_arch = machine_info()
    logging.info('Machine: ' + mach_name + ' ' + mach_arch)
    logging.info('Begin (script ' + __version__ + ')')

    # read boundaries
    boundaries, nested_boundary_ids = read_segments(file_name=boundaries_file, 
          offset=boundaries_offset, ids=boundary_ids, byte_order=boundaries_byte_order,  
          data_type=boundaries_data_type, array_order=boundaries_array_order, 
          shape=boundaries_shape, shift=boundaries_shift)
    boundaries_full_inset = boundaries.inset

    # make layers
    logging.info('Making layers')
    layers = make_layers(segments=boundaries)
    layers.useInset(inset=boundaries.inset, mode='abs', useFull=True, expand=True)

    # pickle layers
    write_layers(layers)

    # read segments
    segments, nested_segment_ids = read_segments(file_name=segments_file, 
          offset=segments_offset, ids=segment_ids, byte_order=segments_byte_order,  
          data_type=segments_data_type, array_order=segments_array_order, 
          shape=segments_shape, shift=segments_shift)

    # read image
    image = read_image()

    # analyze
    logging.info('Starting analysis')
    lay_dens, seg_count, seg_count_vol, overlap = \
              analyze(image=image, layers=layers, segments=segments)

    # write
    write_results(layer_density=lay_dens, layer_ids=layers.ids, segment_count=seg_count,
                  segment_count_per_volume=seg_count_vol, overlap=overlap,
                  nested_segment_ids=nested_segment_ids)

    logging.info('Done')

# run if standalone
if __name__ == '__main__':
    main()

